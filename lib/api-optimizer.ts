/**
 * OPTIMISEUR D'APPELS API
 * v1.0 - 13 janvier 2026
 * 
 * Regroupe (batch) plusieurs appels API similaires en un seul
 * √âvite les requ√™tes redondantes et r√©duit la charge serveur
 */

import { logger } from '../utils/logger';

interface BatchRequest {
  id: string;
  endpoint: string;
  params: any;
  resolve: (data: any) => void;
  reject: (error: any) => void;
  timestamp: number;
}

interface BatchConfig {
  maxBatchSize?: number; // Nombre max de requ√™tes par batch
  maxWaitTime?: number; // Temps max d'attente avant d'envoyer le batch (ms)
}

/**
 * Gestionnaire de batching pour les requ√™tes API
 */
class APIBatcher {
  private queues: Map<string, BatchRequest[]>;
  private timers: Map<string, NodeJS.Timeout>;
  private config: Required<BatchConfig>;

  constructor(config: BatchConfig = {}) {
    this.queues = new Map();
    this.timers = new Map();
    this.config = {
      maxBatchSize: config.maxBatchSize || 10,
      maxWaitTime: config.maxWaitTime || 50 // 50ms
    };
  }

  /**
   * Ajouter une requ√™te √† la queue de batching
   */
  async add<T>(
    endpoint: string,
    params: any,
    fetchFn: (batchParams: any[]) => Promise<T[]>
  ): Promise<T> {
    return new Promise((resolve, reject) => {
      // Cr√©er une queue pour cet endpoint si elle n'existe pas
      if (!this.queues.has(endpoint)) {
        this.queues.set(endpoint, []);
      }

      const queue = this.queues.get(endpoint)!;
      
      // Ajouter la requ√™te √† la queue
      const request: BatchRequest = {
        id: `${endpoint}_${Date.now()}_${Math.random()}`,
        endpoint,
        params,
        resolve,
        reject,
        timestamp: Date.now()
      };
      
      queue.push(request);

      // Si on atteint la taille max, envoyer imm√©diatement
      if (queue.length >= this.config.maxBatchSize) {
        this.flush(endpoint, fetchFn);
      } else {
        // Sinon, d√©marrer/red√©marrer le timer
        this.resetTimer(endpoint, fetchFn);
      }
    });
  }

  /**
   * R√©initialiser le timer pour un endpoint
   */
  private resetTimer(endpoint: string, fetchFn: any): void {
    // Annuler le timer existant
    const existingTimer = this.timers.get(endpoint);
    if (existingTimer) {
      clearTimeout(existingTimer);
    }

    // Cr√©er un nouveau timer
    const timer = setTimeout(() => {
      this.flush(endpoint, fetchFn);
    }, this.config.maxWaitTime);

    this.timers.set(endpoint, timer);
  }

  /**
   * Envoyer toutes les requ√™tes en attente pour un endpoint
   */
  private async flush(endpoint: string, fetchFn: any): Promise<void> {
    const queue = this.queues.get(endpoint);
    if (!queue || queue.length === 0) return;

    // Annuler le timer
    const timer = this.timers.get(endpoint);
    if (timer) {
      clearTimeout(timer);
      this.timers.delete(endpoint);
    }

    // R√©cup√©rer et vider la queue
    const requests = [...queue];
    this.queues.set(endpoint, []);

    logger.debug(`üì¶ Batching ${requests.length} requ√™tes pour ${endpoint}`);

    try {
      // Extraire les param√®tres de toutes les requ√™tes
      const batchParams = requests.map(r => r.params);

      // Appeler la fonction de batch
      const results = await fetchFn(batchParams);

      // R√©soudre chaque promesse avec son r√©sultat
      requests.forEach((request, index) => {
        request.resolve(results[index]);
      });
    } catch (error) {
      // En cas d'erreur, rejeter toutes les promesses
      requests.forEach(request => {
        request.reject(error);
      });
    }
  }

  /**
   * Vider toutes les queues
   */
  async flushAll(): Promise<void> {
    const endpoints = Array.from(this.queues.keys());
    await Promise.all(
      endpoints.map(endpoint => this.flush(endpoint, () => Promise.resolve([])))
    );
  }
}

// Export singleton
export const apiBatcher = new APIBatcher({
  maxBatchSize: 10,
  maxWaitTime: 50
});

/**
 * DEBOUNCE - Limite la fr√©quence d'appel d'une fonction
 */
export function debounce<T extends (...args: any[]) => any>(
  func: T,
  wait: number
): (...args: Parameters<T>) => void {
  let timeout: NodeJS.Timeout | null = null;

  return function executedFunction(...args: Parameters<T>) {
    const later = () => {
      timeout = null;
      func(...args);
    };

    if (timeout) {
      clearTimeout(timeout);
    }

    timeout = setTimeout(later, wait);
  };
}

/**
 * THROTTLE - Garantit qu'une fonction ne s'ex√©cute pas plus d'une fois par intervalle
 */
export function throttle<T extends (...args: any[]) => any>(
  func: T,
  limit: number
): (...args: Parameters<T>) => void {
  let inThrottle: boolean = false;

  return function executedFunction(...args: Parameters<T>) {
    if (!inThrottle) {
      func(...args);
      inThrottle = true;

      setTimeout(() => {
        inThrottle = false;
      }, limit);
    }
  };
}

/**
 * DEDUPLICATE - √âvite les appels identiques simultan√©s
 */
class RequestDeduplicator {
  private pending: Map<string, Promise<any>>;

  constructor() {
    this.pending = new Map();
  }

  /**
   * G√©n√©rer une cl√© unique pour une requ√™te
   */
  private generateKey(endpoint: string, params?: any): string {
    return `${endpoint}::${JSON.stringify(params || {})}`;
  }

  /**
   * Ex√©cuter une requ√™te avec d√©duplication
   */
  async execute<T>(
    endpoint: string,
    fetchFn: () => Promise<T>,
    params?: any
  ): Promise<T> {
    const key = this.generateKey(endpoint, params);

    // Si une requ√™te identique est en cours, retourner la m√™me promesse
    if (this.pending.has(key)) {
      logger.debug(`üîÑ D√©duplication: R√©utilisation de la requ√™te en cours pour ${endpoint}`);
      return this.pending.get(key)!;
    }

    // Cr√©er et stocker la nouvelle promesse
    const promise = fetchFn()
      .finally(() => {
        // Nettoyer apr√®s ex√©cution
        this.pending.delete(key);
      });

    this.pending.set(key, promise);

    return promise;
  }

  /**
   * Annuler toutes les requ√™tes en attente
   */
  clear(): void {
    this.pending.clear();
  }

  /**
   * Obtenir le nombre de requ√™tes en cours
   */
  getPendingCount(): number {
    return this.pending.size;
  }
}

// Export singleton
export const requestDeduplicator = new RequestDeduplicator();

/**
 * Helper combin√©: Cache + D√©duplication + Debounce
 */
export function createOptimizedFetch<T>(
  endpoint: string,
  fetchFn: () => Promise<T>,
  options: {
    cache?: boolean;
    cacheTTL?: number;
    deduplicate?: boolean;
    debounce?: number;
  } = {}
): () => Promise<T> {
  let debouncedFn = fetchFn;

  // Appliquer le debounce si demand√©
  if (options.debounce) {
    let timeoutId: NodeJS.Timeout | null = null;
    let pendingPromise: Promise<T> | null = null;

    debouncedFn = () => {
      if (pendingPromise) return pendingPromise;

      pendingPromise = new Promise((resolve, reject) => {
        if (timeoutId) clearTimeout(timeoutId);

        timeoutId = setTimeout(async () => {
          try {
            const result = await fetchFn();
            resolve(result);
          } catch (error) {
            reject(error);
          } finally {
            pendingPromise = null;
            timeoutId = null;
          }
        }, options.debounce);
      });

      return pendingPromise;
    };
  }

  // Wrapper final
  return async () => {
    if (options.deduplicate) {
      return requestDeduplicator.execute(endpoint, debouncedFn);
    }
    return debouncedFn();
  };
}

/**
 * Statistiques globales
 */
export function getOptimizerStats() {
  return {
    pendingRequests: requestDeduplicator.getPendingCount()
  };
}
